# ================================
# Backend runtime config (dev/demo)
# ================================
# File này sẽ được load bởi backend (Pydantic Settings) khi chạy bằng Docker Compose
# hoặc khi bạn chạy uvicorn từ thư mục backend.
#
# ✅ KHÔNG commit key thật lên Git.

# === OpenAI-compatible API key ===
# - OpenAI Cloud: key bắt đầu bằng "sk-..."
# - MegaLLM: key bắt đầu bằng "sk-mega-..." (vẫn dùng biến OPENAI_API_KEY)
# (Để trống nếu bạn chỉ muốn chạy offline.)
OPENAI_API_KEY=

# OpenAI-compatible base URL (tuỳ chọn)
# - MegaLLM: https://ai.megallm.io/v1
# - Local (Ollama/LM Studio): http://host.docker.internal:11434/v1
# Nếu để trống => mặc định dùng OpenAI cloud (nếu OPENAI_API_KEY là key OpenAI).
OPENAI_BASE_URL=

# Model chat mặc định cho sinh quiz/lesson/tutor
# ✅ Default per request: OpenAI GPT-oss 20B
OPENAI_CHAT_MODEL=openai-gpt-oss-20b

# Optional: model used for a second-pass JSON formatting/extraction.
# Useful for reasoning models that emit <think>/<analysis> text and break JSON parsing.
# Example:
# OPENAI_CHAT_MODEL=deepseek-r1-distill-llama-70b
# OPENAI_JSON_MODEL=openai-gpt-oss-20b
OPENAI_JSON_MODEL=

# ===== Azure OpenAI (optional) =====
# Nếu bạn dùng Azure OpenAI (thay vì OpenAI Cloud/MegaLLM/Ollama), set:
#   AZURE_OPENAI_ENDPOINT=https://<resource>.openai.azure.com/
#   AZURE_OPENAI_API_KEY=<your key>
#   AZURE_OPENAI_API_VERSION=2024-02-15-preview (hoặc api-version bạn chọn)
# và set OPENAI_CHAT_MODEL = tên deployment trên Azure.
AZURE_OPENAI_ENDPOINT=
AZURE_OPENAI_API_KEY=
AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Reasoning effort (chỉ dùng khi provider hỗ trợ Responses API; khuyên dùng none để tương thích rộng)
# Lưu ý: khi effort != none, API có thể không cho phép các tham số như temperature.
OPENAI_REASONING_EFFORT=none

# ===== Optional Auth (Mode A default) =====
AUTH_ENABLED=false
JWT_SECRET_KEY=dev-secret-change-me
JWT_ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=1440

# Điều khiển việc dùng LLM
# - auto: có key thì dùng LLM, không có thì fallback offline
# - llm: luôn cố gắng dùng LLM (thiếu key sẽ fallback)
# - offline: luôn dùng rule-based generator
QUIZ_GEN_MODE=auto
LESSON_GEN_MODE=auto

# Semantic RAG (FAISS + embeddings).
# Lưu ý: MegaLLM docs hiện tập trung vào Chat Completions, không công bố Embeddings endpoint.
# Nếu bạn dùng MegaLLM => nên để false để tránh lỗi embeddings (app sẽ fallback keyword RAG).
SEMANTIC_RAG_ENABLED=false

# === Reranking (2nd-stage refinement for RAG) ===
# Theo tài liệu "Reranking in RAG": rerank giúp tăng precision, giảm noise, và cải thiện chất lượng context.
# Modes: off | llm_judge | auto
RERANK_MODE=auto
RERANK_CANDIDATE_MULTIPLIER=6
RERANK_MAX_CANDIDATES=24
RERANK_MAX_CHARS_PER_CHUNK=850

# ===== OCR / Text-quality guard =====
# If too many chunks are low-quality OCR, the system will refuse to generate quizzes and return NEED_CLEAN_TEXT.
OCR_BAD_CHUNK_RATIO=0.6
OCR_MIN_QUALITY_SCORE=0.45

# ===== PDF extraction =====
# The pipeline tries pdfplumber -> PyMuPDF -> pypdf and picks the best output by quality.
PDF_EXTRACT_MIN_QUALITY_SCORE=0.35

# ===== PDF OCR fallback (scanned/image-only PDFs) =====
PDF_OCR_ENABLED=true
PDF_OCR_LANG=vie+eng
PDF_OCR_MAX_PAGES=200
PDF_OCR_ZOOM=2.5
PDF_OCR_TRIGGER_MIN_QUALITY_SCORE=0.22

# ===== Optional quality loops (LLM refine passes) =====
# Quiz refine (improve wording/distractors/explanations): off | auto | always
QUIZ_LLM_REFINE=auto
QUIZ_LLM_REFINE_MAX_QUESTIONS=20

# Essay refine (teacher-style essay prompts + rubric): off | auto | always
ESSAY_LLM_REFINE=auto
ESSAY_LLM_REFINE_MAX_QUESTIONS=10

# Auto-grade essay answers (no teacher grading): off | auto | always
# - auto: chỉ chấm khi LLM sẵn sàng (OPENAI_API_KEY / OPENAI_BASE_URL)
# - always: luôn chấm. Nếu không có LLM, hệ thống dùng heuristic grader (offline) để trả điểm + nhận xét.
ESSAY_AUTO_GRADE=always
ESSAY_AUTO_GRADE_MIN_CHARS=40

# ===== Topic chuẩn giáo viên (LLM rewrite topic titles) =====
# Rewrite generic/noisy titles like 'Topic 1: keyword...' into teacher-style headings.
# Modes: off | auto | always
# - auto: rewrite only when LLM is available
# - always: always attempt (safe fallback if LLM fails)
TOPIC_LLM_TITLES=auto

# Optional: LLM filter pass to drop/merge/rename extracted topics.
# Modes: off | auto | always
TOPIC_LLM_FILTER=auto

# Keep the "Bài N." prefix in topic titles (true/false)
TOPIC_KEEP_LESSON_PREFIX=false

# PDF heading strategy for topic extraction: auto | topic | chapter
# - auto: try topic/heading split first; if too few topics, fall back to chapter split
# - topic: always use topic/heading split (best for study-guide style like Thea)
# - chapter: only split by chapters (coarser)
TOPIC_PDF_HEADING_LEVEL=auto

# Thea-like Study Guide generation mode:
# - json: strict structured output (may be brittle on some OpenAI-compatible servers)
# - markdown: robust plain-text markdown guide (recommended for Ollama/OpenAI-compatible gateways)
TOPIC_STUDY_GUIDE_MODE=markdown

# When listing topics with detail=1, how many topics are allowed to call LLM for richer study guides.
TOPIC_LLM_VIEW_MAX_TOPICS=20

# Max topics kept (preserve order)
TOPIC_MAX_TOPICS=60

# Numeric heading depth cap for topic boundaries.
# Example: depth=2 allows "2.3" but NOT "2.3.1" to become a new topic.
TOPIC_NUM_HEADING_MAX_DEPTH=2

# Minimum body size (in chars) for a topic.
# Topics below this threshold will be merged with adjacent topics so each topic
# has enough evidence for study material + multi-level question generation.
TOPIC_MIN_BODY_CHARS=2200

# Lesson-mode topic splitting: off | auto | always
TOPIC_LESSON_MODE=auto

# Hide appendix sections ("Phụ lục" / "Appendix") from UI topic lists.
TOPIC_HIDE_APPENDIX=true

# ===== Optional: external enrichment for "Ít dữ liệu" topics =====
# Modes: off | auto | always
# - auto: chỉ bổ sung khi topic quá ngắn hoặc có marker "Ít dữ liệu".
# Nguồn hiện tại: Wikipedia summary (kèm URL rõ ràng).
TOPIC_EXTERNAL_ENRICH=auto
TOPIC_EXTERNAL_MIN_BODY_CHARS=900
TOPIC_EXTERNAL_MAX_SOURCES=2
TOPIC_EXTERNAL_WIKI_LANG=vi
TOPIC_EXTERNAL_TIMEOUT_SEC=6

# ===== Topic -> Exam readiness =====
# Ensure every extracted topic has enough evidence to generate quizzes/exams (even when doing a mixed-topic exam).
# The system may expand each topic's chunk-range (allowing overlaps) until it meets these minima.
TOPIC_MIN_CHUNKS_FOR_QUIZ=4
TOPIC_MIN_CHARS_FOR_QUIZ=1400
TOPIC_MAX_EXPAND_CHUNKS=6

# === (Tuỳ chọn) LLM local tương thích OpenAI (Ollama/LM Studio) ===
# Nếu muốn dùng local, hãy uncomment và thay model cho phù hợp.
# OPENAI_BASE_URL=http://host.docker.internal:11434/v1
# OPENAI_CHAT_MODEL=moonshotai/kimi-k2-thinking
# SEMANTIC_RAG_ENABLED=false

# === (Tuỳ chọn) MegaLLM (chat-only) ===
# Lưu ý: MegaLLM thường không có Embeddings endpoint công khai.
# => Nếu dùng MegaLLM, nên để SEMANTIC_RAG_ENABLED=false để tránh lỗi embeddings (app vẫn chạy Keyword RAG + rerank).
# OPENAI_BASE_URL=https://ai.megallm.io/v1
# OPENAI_CHAT_MODEL=claude-opus-4-5-20251101
# SEMANTIC_RAG_ENABLED=false

# === (Tuỳ chọn) Alibaba Cloud Model Studio (DashScope) / Qwen ===
# DashScope hỗ trợ API tương thích OpenAI.
# - Singapore/International: https://dashscope-intl.aliyuncs.com/compatible-mode/v1
# - China (Beijing):        https://dashscope.aliyuncs.com/compatible-mode/v1
# - US (Virginia):          https://dashscope-us.aliyuncs.com/compatible-mode/v1
#
# Ví dụ (Qwen chat):
# OPENAI_API_KEY=<DASHSCOPE_API_KEY>
# OPENAI_BASE_URL=https://dashscope-intl.aliyuncs.com/compatible-mode/v1
# OPENAI_CHAT_MODEL=qwen-plus
#
# Nếu bạn dùng Qwen3/Qwen3.5 hybrid-thinking models và gặp lỗi JSON (đầu ra có reasoning_content / rác),
# hãy tắt thinking mode để ổn định JSON:
# QWEN_ENABLE_THINKING=false
# (tuỳ chọn) Giới hạn token cho thinking:
# QWEN_THINKING_BUDGET=0
#
# Nếu muốn bật Semantic RAG (embeddings) với DashScope:
# SEMANTIC_RAG_ENABLED=true
# OPENAI_EMBEDDING_MODEL=text-embedding-v3

# === Advanced (OpenAI-compatible) ===
# Một số provider cần headers/query/body tuỳ biến.
# Bạn có thể set dạng JSON string:
# OPENAI_EXTRA_HEADERS_JSON={"X-Foo":"bar"}
# OPENAI_EXTRA_QUERY_JSON={"foo":"bar"}
# OPENAI_EXTRA_BODY_JSON={"enable_thinking":false}

# (Ví dụ) nếu bạn dùng gateway đặt model id là: alibaba-qwen3.5-397b
# thì chỉ cần set OPENAI_CHAT_MODEL=alibaba-qwen3.5-397b (base_url/key theo gateway của bạn).

# ===== Optional: Evaluation Toolkit =====
# To enable RAG evaluation tooling (DeepEval/Ragas), install: pip install -r ../requirements.toolkit.txt


# ===== Teacher-style Learning Plan (7-day) =====
# LEARNING_PLAN_MODE:
#   auto: ưu tiên bám sát document_topics (mục lục giáo viên) nếu có; nếu không fallback theo weak topics
#   teacher_topics: luôn ưu tiên bám sát document_topics
#   weak_topics: bám theo các topic yếu từ bài test đầu vào (fallback)
#   off: tắt teacher_plan
LEARNING_PLAN_MODE=auto
LEARNING_PLAN_DAYS=7
LEARNING_PLAN_MINUTES_PER_DAY=35

# ===== Homework (daily essay) =====
HOMEWORK_LLM_GEN=auto
HOMEWORK_AUTO_GRADE=always
# (tương tự ESSAY_AUTO_GRADE) HOMEWORK_AUTO_GRADE=always sẽ chấm offline (heuristic) nếu không có LLM.
HOMEWORK_MIN_CHARS=40
HOMEWORK_MAX_POINTS=10

# LLM status endpoint test settings
OPENAI_STATUS_TEST_TIMEOUT_SEC=20
OPENAI_STATUS_TEST_MAX_TOKENS=256

# Async queue (Redis/RQ)
ASYNC_QUEUE_ENABLED=false
REDIS_URL=redis://localhost:6379/0
RQ_DEFAULT_TIMEOUT_SEC=1800
